import * as path from 'path';
import * as fs from 'fs/promises';
import { $, withTempDir } from '@xec-sh/core';
async function databaseBackup(config) {
    console.log('\n=== –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ===\n');
    console.log(`–ë–∞–∑–∞: ${config.database}`);
    console.log(`–¢–∏–ø: ${config.type}`);
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const backupName = `${config.database}-${timestamp}`;
    try {
        await $ `mkdir -p ${config.backupPath}`;
        let backupFile;
        switch (config.type) {
            case 'postgresql':
                backupFile = await backupPostgreSQL(config, backupName);
                break;
            case 'mysql':
                backupFile = await backupMySQL(config, backupName);
                break;
            case 'mongodb':
                backupFile = await backupMongoDB(config, backupName);
                break;
            default:
                throw new Error(`Unsupported database type: ${config.type}`);
        }
        console.log('\nüì¶ –°–∂–∞—Ç–∏–µ –±—ç–∫–∞–ø–∞...');
        const compressedFile = `${backupFile}.gz`;
        await $ `gzip -9 ${backupFile}`;
        const stats = await fs.stat(compressedFile);
        console.log(`‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: ${path.basename(compressedFile)}`);
        console.log(`   –†–∞–∑–º–µ—Ä: ${formatBytes(stats.size)}`);
        if (config.uploadToCloud) {
            await uploadBackupToCloud(compressedFile, config.cloudStorage);
        }
        await cleanupOldBackups(config.backupPath, config.retentionDays);
        await sendBackupNotification(config, {
            status: 'success',
            file: compressedFile,
            size: stats.size,
            duration: Date.now() - Date.parse(timestamp)
        });
        return compressedFile;
    }
    catch (error) {
        console.error('‚ùå –û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è:', error.message);
        await sendBackupNotification(config, {
            status: 'failed',
            error: error.message
        });
        throw error;
    }
}
async function backupPostgreSQL(config, backupName) {
    console.log('\nüêò PostgreSQL –±—ç–∫–∞–ø...');
    const backupFile = path.join(config.backupPath, `${backupName}.sql`);
    const $pg = $.with({
        env: {
            PGPASSWORD: config.password,
            PGHOST: config.host,
            PGPORT: config.port || '5432',
            PGUSER: config.username
        }
    });
    await $pg `pg_isready`;
    console.log('–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...');
    if (config.includeLargeObjects) {
        await $pg `pg_dump -d ${config.database} -b -v -f ${backupFile}`;
    }
    else {
        await $pg `pg_dump -d ${config.database} -v -f ${backupFile}`;
    }
    console.log('‚úÖ –î–∞–º–ø —Å–æ–∑–¥–∞–Ω');
    if (config.includeRoles) {
        const rolesFile = path.join(config.backupPath, `${backupName}-roles.sql`);
        await $pg `pg_dumpall -r -f ${rolesFile}`;
        console.log('‚úÖ –†–æ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã');
    }
    return backupFile;
}
async function backupMySQL(config, backupName) {
    console.log('\nüê¨ MySQL –±—ç–∫–∞–ø...');
    const backupFile = path.join(config.backupPath, `${backupName}.sql`);
    const options = [
        `--host=${config.host}`,
        `--port=${config.port || 3306}`,
        `--user=${config.username}`,
        `--password=${config.password}`,
        '--single-transaction',
        '--routines',
        '--triggers'
    ];
    if (config.includeLargeObjects) {
        options.push('--hex-blob');
    }
    console.log('–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...');
    await $ `mysqldump ${options} ${config.database} > ${backupFile}`;
    console.log('‚úÖ –î–∞–º–ø —Å–æ–∑–¥–∞–Ω');
    return backupFile;
}
async function backupMongoDB(config, backupName) {
    console.log('\nüçÉ MongoDB –±—ç–∫–∞–ø...');
    const backupDir = path.join(config.backupPath, backupName);
    const authPart = config.username ? `${config.username}:${config.password}@` : '';
    const uri = `mongodb://${authPart}${config.host}:${config.port || 27017}/${config.database}`;
    console.log('–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...');
    await $ `mongodump --uri="${uri}" --out="${backupDir}"`;
    console.log('‚úÖ –î–∞–º–ø —Å–æ–∑–¥–∞–Ω');
    const archiveFile = `${backupDir}.tar`;
    await $ `tar -cf ${archiveFile} -C ${config.backupPath} ${backupName}`;
    await $ `rm -rf ${backupDir}`;
    return archiveFile;
}
async function databaseRestore(config) {
    console.log('\n=== –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ===\n');
    try {
        await fs.access(config.backupFile);
    }
    catch {
        throw new Error(`–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: ${config.backupFile}`);
    }
    if (!config.force) {
        console.log(`‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã ${config.database} –∏–∑ –±—ç–∫–∞–ø–∞.`);
        console.log('–í—Å–µ —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –ø–æ—Ç–µ—Ä—è–Ω—ã!');
        console.log('–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä force: true –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.');
        const confirm = false;
        if (!confirm) {
            console.log('–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ');
            return;
        }
    }
    return await withTempDir(async (tmpDir) => {
        let sqlFile = config.backupFile;
        if (config.backupFile.endsWith('.gz')) {
            console.log('üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –±—ç–∫–∞–ø–∞...');
            sqlFile = path.join(tmpDir.path, path.basename(config.backupFile, '.gz'));
            await $ `gunzip -c ${config.backupFile} > ${sqlFile}`;
        }
        else if (config.backupFile.endsWith('.tar')) {
            console.log('üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞...');
            await $ `tar -xf ${config.backupFile} -C ${tmpDir.path}`;
            const files = await fs.readdir(tmpDir.path);
            sqlFile = path.join(tmpDir.path, files[0]);
        }
        switch (config.type) {
            case 'postgresql':
                await restorePostgreSQL(config, sqlFile);
                break;
            case 'mysql':
                await restoreMySQL(config, sqlFile);
                break;
            case 'mongodb':
                await restoreMongoDB(config, sqlFile);
                break;
        }
        console.log('\n‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!');
    });
}
async function restorePostgreSQL(config, sqlFile) {
    console.log('\nüêò –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ PostgreSQL...');
    const $pg = $.with({
        env: {
            PGPASSWORD: config.password,
            PGHOST: config.host,
            PGPORT: config.port || '5432',
            PGUSER: config.username
        }
    });
    if (config.dropExisting) {
        console.log('–£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –±–∞–∑—ã...');
        await $pg `dropdb --if-exists ${config.database}`;
        await $pg `createdb ${config.database}`;
    }
    const spinner = interactive.spinner('–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...');
    spinner.start();
    await $pg `psql -d ${config.database} -f ${sqlFile}`;
    spinner.succeed('–î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã');
    console.log('–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü...');
    await $pg `vacuumdb -d ${config.database} -z`;
}
async function restoreMySQL(config, sqlFile) {
    console.log('\nüê¨ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ MySQL...');
    const mysqlAuth = [
        `--host=${config.host}`,
        `--port=${config.port || 3306}`,
        `--user=${config.username}`,
        `--password=${config.password}`
    ];
    if (config.dropExisting) {
        console.log('–£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –±–∞–∑—ã...');
        await $ `mysql ${mysqlAuth} -e "DROP DATABASE IF EXISTS ${config.database}"`;
        await $ `mysql ${mysqlAuth} -e "CREATE DATABASE ${config.database}"`;
    }
    const spinner = interactive.spinner('–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...');
    spinner.start();
    await $ `mysql ${mysqlAuth} ${config.database} < ${sqlFile}`;
    spinner.succeed('–î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã');
}
async function restoreMongoDB(config, dumpDir) {
    console.log('\nüçÉ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ MongoDB...');
    const authPart = config.username ? `${config.username}:${config.password}@` : '';
    const uri = `mongodb://${authPart}${config.host}:${config.port || 27017}/${config.database}`;
    const spinner = interactive.spinner('–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...');
    spinner.start();
    const options = [`--uri="${uri}"`];
    if (config.dropExisting) {
        options.push('--drop');
    }
    await $ `mongorestore ${options} ${dumpDir}`;
    spinner.succeed('–î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã');
}
async function runDatabaseMigrations(config) {
    console.log('\n=== –ú–∏–≥—Ä–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ===\n');
    const pendingMigrations = await getPendingMigrations(config);
    if (pendingMigrations.length === 0) {
        console.log('‚úÖ –í—Å–µ –º–∏–≥—Ä–∞—Ü–∏–∏ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã');
        return;
    }
    console.log(`–ù–∞–π–¥–µ–Ω–æ ${pendingMigrations.length} –Ω–æ–≤—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π:`);
    pendingMigrations.forEach(m => console.log(`  - ${m.name}`));
    if (config.backupBeforeMigration) {
        console.log('\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π...');
        const backupConfig = {
            ...config,
            backupPath: path.join(config.migrationsPath, 'backups')
        };
        await databaseBackup(backupConfig);
    }
    let applied = 0;
    const results = [];
    for (const migration of pendingMigrations) {
        try {
            await applyMigration(config, migration);
            results.push({ migration: migration.name, status: 'success' });
            applied++;
            process.stdout.write(`\r–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –º–∏–≥—Ä–∞—Ü–∏–π: ${applied}/${pendingMigrations.length}`);
        }
        catch (error) {
            results.push({ migration: migration.name, status: 'failed', error: error.message });
            console.log('');
            if (config.stopOnError) {
                console.error(`\n‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ ${migration.name}:`, error.message);
                if (config.rollbackOnError) {
                    await rollbackMigrations(config, results.filter(r => r.status === 'success').map(r => r.migration));
                }
                throw error;
            }
        }
    }
    progressBar.stop();
    console.log('\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏:');
    results.forEach(r => {
        const icon = r.status === 'success' ? '‚úÖ' : '‚ùå';
        console.log(`${icon} ${r.migration}`);
        if (r.error) {
            console.log(`   –û—à–∏–±–∫–∞: ${r.error}`);
        }
    });
}
async function getPendingMigrations(config) {
    const files = await fs.readdir(config.migrationsPath);
    const migrationFiles = files
        .filter(f => f.endsWith('.sql'))
        .sort();
    const appliedMigrations = await getAppliedMigrations(config);
    const pendingMigrations = migrationFiles
        .filter(f => !appliedMigrations.includes(f))
        .map(f => ({
        name: f,
        path: path.join(config.migrationsPath, f)
    }));
    return pendingMigrations;
}
async function getAppliedMigrations(config) {
    const $db = getDatabaseClient(config);
    await createMigrationsTable($db, config);
    let result;
    switch (config.type) {
        case 'postgresql':
            result = await $db `psql -d ${config.database} -t -c "SELECT migration_name FROM migrations ORDER BY applied_at"`;
            break;
        case 'mysql':
            result = await $db `mysql ${config.database} -N -e "SELECT migration_name FROM migrations ORDER BY applied_at"`;
            break;
    }
    return result.stdout
        .trim()
        .split('\n')
        .filter(Boolean)
        .map(line => line.trim());
}
async function createMigrationsTable($db, config) {
    const createTableSQL = `
    CREATE TABLE IF NOT EXISTS migrations (
      id SERIAL PRIMARY KEY,
      migration_name VARCHAR(255) UNIQUE NOT NULL,
      applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
  `;
    switch (config.type) {
        case 'postgresql':
            await $db `psql -d ${config.database} -c "${createTableSQL}"`;
            break;
        case 'mysql':
            await $db `mysql ${config.database} -e "${createTableSQL}"`;
            break;
    }
}
async function applyMigration(config, migration) {
    console.log(`\n‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ ${migration.name}...`);
    const $db = getDatabaseClient(config);
    const migrationContent = await fs.readFile(migration.path, 'utf-8');
    const transaction = wrapInTransaction(migrationContent, config.type);
    switch (config.type) {
        case 'postgresql':
            await $db `psql -d ${config.database} -c "${transaction}"`;
            break;
        case 'mysql':
            await $db `mysql ${config.database} -e "${transaction}"`;
            break;
    }
    const recordSQL = `INSERT INTO migrations (migration_name) VALUES ('${migration.name}')`;
    switch (config.type) {
        case 'postgresql':
            await $db `psql -d ${config.database} -c "${recordSQL}"`;
            break;
        case 'mysql':
            await $db `mysql ${config.database} -e "${recordSQL}"`;
            break;
    }
}
function wrapInTransaction(sql, dbType) {
    switch (dbType) {
        case 'postgresql':
            return `BEGIN;\n${sql}\nCOMMIT;`;
        case 'mysql':
            return `START TRANSACTION;\n${sql}\nCOMMIT;`;
        default:
            return sql;
    }
}
async function rollbackMigrations(config, migrations) {
    console.log('\nüîÑ –û—Ç–∫–∞—Ç –º–∏–≥—Ä–∞—Ü–∏–π...');
    for (const migrationName of migrations.reverse()) {
        console.log(`  –û—Ç–∫–∞—Ç ${migrationName}...`);
        const rollbackFile = migrationName.replace('.sql', '.rollback.sql');
        const rollbackPath = path.join(config.migrationsPath, rollbackFile);
        try {
            await fs.access(rollbackPath);
            const migration = {
                name: rollbackFile,
                path: rollbackPath
            };
            await applyMigration(config, migration);
            const $db = getDatabaseClient(config);
            const deleteSQL = `DELETE FROM migrations WHERE migration_name = '${migrationName}'`;
            switch (config.type) {
                case 'postgresql':
                    await $db `psql -d ${config.database} -c "${deleteSQL}"`;
                    break;
                case 'mysql':
                    await $db `mysql ${config.database} -e "${deleteSQL}"`;
                    break;
            }
        }
        catch (error) {
            console.error(`  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –æ—Ç–∫–∞—Ç–∞ –¥–ª—è ${migrationName}`);
        }
    }
}
async function monitorDatabasePerformance(config) {
    console.log('\n=== –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ë–î ===\n');
    const interval = 5000;
    const duration = 60000;
    const startTime = Date.now();
    const metrics = [];
    while (Date.now() - startTime < duration) {
        const metric = await collectDatabaseMetrics(config);
        metrics.push(metric);
        console.clear();
        console.log('=== –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ë–î ===\n');
        console.log(`–ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: ${metric.activeConnections}`);
        console.log(`–ó–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: ${metric.queriesPerSecond}`);
        console.log(`–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞: ${metric.avgLatency}ms`);
        console.log(`–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏: ${metric.locks}`);
        if (config.type === 'postgresql') {
            console.log(`\n–¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏:`);
            metric.slowQueries.forEach((q, i) => {
                console.log(`${i + 1}. ${q.duration}ms - ${q.query.substring(0, 50)}...`);
            });
        }
        await new Promise(resolve => setTimeout(resolve, interval));
    }
    analyzeDatabaseMetrics(metrics);
}
async function collectDatabaseMetrics(config) {
    const $db = getDatabaseClient(config);
    switch (config.type) {
        case 'postgresql':
            return await collectPostgreSQLMetrics($db, config);
        case 'mysql':
            return await collectMySQLMetrics($db, config);
        default:
            throw new Error(`Unsupported database type: ${config.type}`);
    }
}
async function collectPostgreSQLMetrics($db, config) {
    const connections = await $db `psql -d ${config.database} -t -c "SELECT count(*) FROM pg_stat_activity"`;
    const stats = await $db `psql -d ${config.database} -t -c "SELECT sum(calls) as total_calls, sum(total_time) as total_time FROM pg_stat_statements"`;
    const locks = await $db `psql -d ${config.database} -t -c "SELECT count(*) FROM pg_locks WHERE granted = false"`;
    const slowQueries = await $db `psql -d ${config.database} -t -c "
    SELECT query, total_time/calls as avg_time 
    FROM pg_stat_statements 
    WHERE calls > 0 
    ORDER BY avg_time DESC 
    LIMIT 5
  "`.then(r => r.stdout.trim().split('\n').filter(Boolean).map(line => {
        const [query, duration] = line.split('|').map(s => s.trim());
        return { query, duration: parseFloat(duration) };
    }));
    return {
        activeConnections: parseInt(connections.stdout.trim()),
        queriesPerSecond: 0,
        avgLatency: 0,
        locks: parseInt(locks.stdout.trim()),
        slowQueries
    };
}
async function collectMySQLMetrics($db, config) {
    const connections = await $db `mysql ${config.database} -N -e "SHOW STATUS LIKE 'Threads_connected'" | awk '{print $2}'`;
    const queries = await $db `mysql ${config.database} -N -e "SHOW STATUS LIKE 'Questions'" | awk '{print $2}'`;
    const locks = await $db `mysql ${config.database} -N -e "SELECT COUNT(*) FROM information_schema.INNODB_LOCKS"`;
    return {
        activeConnections: parseInt(connections.stdout.trim()),
        queriesPerSecond: 0,
        avgLatency: 0,
        locks: parseInt(locks.stdout.trim()),
        slowQueries: []
    };
}
function analyzeDatabaseMetrics(metrics) {
    console.log('\n\n=== –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ===\n');
    const avgConnections = average(metrics.map(m => m.activeConnections));
    const maxConnections = Math.max(...metrics.map(m => m.activeConnections));
    const avgLocks = average(metrics.map(m => m.locks));
    console.log(`–°–æ–µ–¥–∏–Ω–µ–Ω–∏—è:`);
    console.log(`  –°—Ä–µ–¥–Ω–µ–µ: ${avgConnections.toFixed(1)}`);
    console.log(`  –ú–∞–∫—Å–∏–º—É–º: ${maxConnections}`);
    console.log(`\n–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏:`);
    console.log(`  –°—Ä–µ–¥–Ω–µ–µ: ${avgLocks.toFixed(1)}`);
    console.log('\nüìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:');
    if (avgConnections > 100) {
        console.log('- –í—ã—Å–æ–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π');
    }
    if (avgLocks > 10) {
        console.log('- –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —á–∞—Å—Ç—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏');
    }
}
async function optimizeDatabase(config) {
    console.log('\n=== –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ===\n');
    const tasks = [];
    switch (config.type) {
        case 'postgresql':
            tasks.push({ name: 'VACUUM ANALYZE', fn: () => vacuumPostgreSQL(config) }, { name: '–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏', fn: () => updatePostgreSQLStats(config) }, { name: '–ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤', fn: () => findUnusedIndexes(config) }, { name: '–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü', fn: () => analyzeTableSizes(config) });
            break;
        case 'mysql':
            tasks.push({ name: 'OPTIMIZE TABLES', fn: () => optimizeMySQL(config) }, { name: '–ê–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏', fn: () => analyzeMySQLFragmentation(config) }, { name: '–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤', fn: () => checkMySQLIndexes(config) });
            break;
    }
    for (const task of tasks) {
        console.log(`\nüìä ${task.name}...`);
        try {
            await task.fn();
        }
        catch (error) {
            console.error(`‚ùå –û—à–∏–±–∫–∞: ${error.message}`);
        }
    }
}
async function vacuumPostgreSQL(config) {
    const $db = getDatabaseClient(config);
    const tables = await $db `psql -d ${config.database} -t -c "
    SELECT schemaname || '.' || tablename 
    FROM pg_tables 
    WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
  "`;
    const tableList = tables.stdout.trim().split('\n').filter(Boolean);
    let processed = 0;
    for (const table of tableList) {
        await $db `psql -d ${config.database} -c "VACUUM ANALYZE ${table.trim()}"`;
        processed++;
        process.stdout.write(`\rVACUUM —Ç–∞–±–ª–∏—Ü: ${processed}/${tableList.length}`);
    }
    progressBar.stop();
    console.log(`‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: ${tableList.length}`);
}
async function updatePostgreSQLStats(config) {
    const $db = getDatabaseClient(config);
    await $db `psql -d ${config.database} -c "ANALYZE"`;
    console.log('‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞');
}
async function findUnusedIndexes(config) {
    const $db = getDatabaseClient(config);
    const unusedIndexes = await $db `psql -d ${config.database} -t -c "
    SELECT schemaname || '.' || indexname AS index_name,
           pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
    FROM pg_stat_user_indexes
    WHERE idx_scan = 0
    AND schemaname NOT IN ('pg_catalog', 'information_schema')
    ORDER BY pg_relation_size(indexrelid) DESC
  "`;
    const indexes = unusedIndexes.stdout.trim().split('\n').filter(Boolean);
    if (indexes.length > 0) {
        console.log('‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã:');
        indexes.forEach(idx => {
            const [name, size] = idx.split('|').map(s => s.trim());
            console.log(`  - ${name} (${size})`);
        });
    }
    else {
        console.log('‚úÖ –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ');
    }
}
async function analyzeTableSizes(config) {
    const $db = getDatabaseClient(config);
    const tableSizes = await $db `psql -d ${config.database} -t -c "
    SELECT schemaname || '.' || tablename AS table_name,
           pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
           pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size
    FROM pg_tables
    WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
    LIMIT 10
  "`;
    console.log('üìä –¢–æ–ø 10 —Ç–∞–±–ª–∏—Ü –ø–æ —Ä–∞–∑–º–µ—Ä—É:');
    console.log('–¢–∞–±–ª–∏—Ü–∞ | –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä | –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö');
    console.log('-'.repeat(50));
    tableSizes.stdout.trim().split('\n').filter(Boolean).forEach(line => {
        const [table, total, data] = line.split('|').map(s => s.trim());
        console.log(`${table} | ${total} | ${data}`);
    });
}
async function optimizeMySQL(config) {
    const $db = getDatabaseClient(config);
    const tables = await $db `mysql ${config.database} -N -e "SHOW TABLES"`;
    const tableList = tables.stdout.trim().split('\n').filter(Boolean);
    let optimized = 0;
    for (const table of tableList) {
        await $db `mysql ${config.database} -e "OPTIMIZE TABLE ${table}"`;
        optimized++;
        process.stdout.write(`\r–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü: ${optimized}/${tableList.length}`);
    }
    progressBar.stop();
    console.log(`‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: ${tableList.length}`);
}
async function analyzeMySQLFragmentation(config) {
    const $db = getDatabaseClient(config);
    const fragmentation = await $db `mysql ${config.database} -e "
    SELECT TABLE_NAME, 
           ROUND(DATA_FREE/1024/1024, 2) AS fragmentation_mb
    FROM information_schema.TABLES
    WHERE TABLE_SCHEMA = '${config.database}'
    AND DATA_FREE > 0
    ORDER BY DATA_FREE DESC
  "`;
    console.log('üìä –§—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü:');
    console.log(fragmentation.stdout);
}
async function checkMySQLIndexes(config) {
    const $db = getDatabaseClient(config);
    const duplicates = await $db `mysql ${config.database} -e "
    SELECT TABLE_NAME, GROUP_CONCAT(INDEX_NAME) AS duplicate_indexes
    FROM information_schema.STATISTICS
    WHERE TABLE_SCHEMA = '${config.database}'
    GROUP BY TABLE_NAME, COLUMN_NAME
    HAVING COUNT(*) > 1
  "`;
    if (duplicates.stdout.trim().split('\n').length > 1) {
        console.log('‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∏–Ω–¥–µ–∫—Å—ã:');
        console.log(duplicates.stdout);
    }
    else {
        console.log('‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ');
    }
}
function getDatabaseClient(config) {
    switch (config.type) {
        case 'postgresql':
            return $.with({
                env: {
                    PGPASSWORD: config.password,
                    PGHOST: config.host,
                    PGPORT: config.port || '5432',
                    PGUSER: config.username
                }
            });
        case 'mysql':
            return $.with({
                env: {
                    MYSQL_PWD: config.password
                }
            });
        default:
            return $;
    }
}
async function uploadBackupToCloud(backupFile, cloudConfig) {
    console.log('\n‚òÅÔ∏è  –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –æ–±–ª–∞–∫–æ...');
    switch (cloudConfig.provider) {
        case 's3':
            await $ `aws s3 cp ${backupFile} s3://${cloudConfig.bucket}/${path.basename(backupFile)}`;
            break;
        case 'gcs':
            await $ `gsutil cp ${backupFile} gs://${cloudConfig.bucket}/${path.basename(backupFile)}`;
            break;
        case 'azure':
            await $ `az storage blob upload -f ${backupFile} -c ${cloudConfig.container} -n ${path.basename(backupFile)}`;
            break;
    }
    console.log('‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤ –æ–±–ª–∞–∫–æ');
}
async function cleanupOldBackups(backupPath, retentionDays) {
    console.log('\nüóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤...');
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    const files = await fs.readdir(backupPath);
    let deletedCount = 0;
    for (const file of files) {
        const filePath = path.join(backupPath, file);
        const stats = await fs.stat(filePath);
        if (stats.mtime < cutoffDate) {
            await fs.unlink(filePath);
            deletedCount++;
        }
    }
    if (deletedCount > 0) {
        console.log(`‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤: ${deletedCount}`);
    }
}
async function sendBackupNotification(config, result) {
    if (!config.notifications)
        return;
    const message = result.status === 'success'
        ? `‚úÖ –ë—ç–∫–∞–ø ${config.database} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω\n–§–∞–π–ª: ${path.basename(result.file)}\n–†–∞–∑–º–µ—Ä: ${formatBytes(result.size)}`
        : `‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ ${config.database}\n${result.error}`;
    console.log('\nüìß –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ:', message);
}
function formatBytes(bytes) {
    const units = ['B', 'KB', 'MB', 'GB', 'TB'];
    let size = bytes;
    let unitIndex = 0;
    while (size >= 1024 && unitIndex < units.length - 1) {
        size /= 1024;
        unitIndex++;
    }
    return `${size.toFixed(2)} ${units[unitIndex]}`;
}
function average(numbers) {
    return numbers.reduce((a, b) => a + b, 0) / numbers.length;
}
export { databaseBackup, databaseRestore, optimizeDatabase, runDatabaseMigrations, monitorDatabasePerformance };
//# sourceMappingURL=05-database-operations.js.map